---
layout:     post
title:      爬虫小练习及代码
subtitle:   包括爬取斗破全文，爬取酷狗top500,爬取小猪短租网信息
date:       2020-03-25
author:     HB
header-img: img/post-bg-crawler.jpg
catalog: true
tags:
    - Web Crawler
---



##  斗破
```Python
import requests
from bs4 import BeautifulSoup
import time
import re

headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 Edg/80.0.361.69'
}
#"a" - Append - Opens a file for appending, creates the file if it does not exist
f = open('doupo.txt','a+')

def get_info(url):
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        #'*':匹配前一个字符0或无限次，'?' :匹配前一个字符0或一次，re.S:使匹配包括换行在内的所有字符
        contents = re.findall('<p>(.*?)</p>',res.content.decode('utf-8'),re.S)
        for content in contents:
            f.write(content+'\n')
        else:
            pass


if __name__ == '__main__':
    urls = ['http://www.doupoxs.com/doupocangqiong/{}.html'.format(number) for number in range(1,1625)]
    for url in urls:
        get_info(url)
        time.sleep(1)
f.close()
```
## 酷狗

```Python

import requests
from bs4 import BeautifulSoup
import time

headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 Edg/80.0.361.69'
}


def get_info(url):
    web_data = requests.get(url, headers=headers)
    soup = BeautifulSoup(web_data.text, 'lxml')

    #注意： 本案 例 并未 完全 使用“ Copy selector” 的 全部 信息， 由于 有些 标签 是 固定 的， 因此 选用 部分 路径 即可。
    rankings = soup.select('span.pc_temp_num')
    music = soup.select('div.pc_temp_songlist > ul > li > a')
    ts = soup.select('span.pc_temp_tips_r > span')

    for ranking, music, t in zip(rankings, music, ts):
        data = {
            """The strip() method removes any leading (spaces at the beginning) and
            trailing (spaces at the end) characters (space is the default leading character to remove)"""
            'ranking':ranking.get_text().strip(),
            'music'  : music.get_text(),
            't'      : t.get_text().strip()
        }
        print(data)

if __name__ == '__main__':
    urls = ['https://www.kugou.com/yy/rank/home/{}-8888.html?from=rank'.format(number) for number in range(1,25)]
    for url in urls:
        get_info(url)
        time.sleep(1)
```

## 小猪

```Python

import requests
from bs4 import BeautifulSoup
import time

headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 Edg/80.0.361.69'
}
def judgement_sex(class_name):
    if class_name == "member_girl_ico":
        return '女'
    else:
        return '男'


def get_links(url):
    web_data = requests.get(url,headers = headers)
    soup = BeautifulSoup(web_data.text,'lxml')
    links = soup.select('#page_list > ul > li > a')
    for link in links:
        href = link.get("href")
        get_info(href)


def get_info(url):
    web_data = requests.get(url, headers=headers)
    soup = BeautifulSoup(web_data.text, 'lxml')
    tittles = soup.select('div.pho_info > h4')
    addresses = soup.select('span.pr5')

    for tittle, address in zip(tittles,addresses):
        data = {
            'tittle': tittle.get_text().strip(),
            'address': address.get_text().strip()
        }
        print(data)
if __name__ == '__main__':
    urls = ['http://bj.xiaozhu.com/search-duanzufang-p{}-0/'.format(number) for number in range(1,14)]
    for url in urls:
        get_links(url)
        time.sleep(2)
```
### 参考书目：
- 罗攀; 蒋仟. 《从零开始学Python网络爬虫》. 北京华章图文信息有限公司. Kindle 版本. 
